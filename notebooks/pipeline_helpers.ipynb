{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Requirements\n",
    "\n",
    "- Putting src data from BQ, into the workspace bucket\n",
    "- id_rsa key and placement in the ~ directory in Terra\n",
    "- Study specific dirs created in the workspace bucket. \n",
    "\n",
    "# Data requirements\n",
    " - src datafiles are in the study specific workspace bucket dir\n",
    "   - if outside of the workspace bring them in. Functions exist to create the sql needed to get the data into the workspace, to be run in the projects BigQuery Console.\n",
    " - {study_id}_validation.yaml exists \n",
    "\n",
    "# Process\n",
    "- Don't run all the cells at once without reviewing them, parameters toward the bottom, will need to be updated first.\n",
    "\n",
    "\n",
    "### TODOs\n",
    "- Make this a terra workflow(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = 'anvil_dbt_project'\n",
    "repo='git@github.com:NIH-NCPI/anvil_dbt_project.git' #The ssh version\n",
    "study_id = ''\n",
    "org_id = 'anvil'\n",
    "dbt_repo = 'anvil_dbt_project'\n",
    "tgt_model_id = 'tgt_consensus_a'\n",
    "\n",
    "ftd_schema = f'main_{study_id}_data'\n",
    "tgt_schema = f'main_{study_id}_tgt_data'\n",
    "\n",
    "gh_email = ''\n",
    "gh_user = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "from pathlib import Path\n",
    "import os\n",
    "import pandas as pd\n",
    "import duckdb\n",
    "from jinja2 import Template\n",
    "import sys\n",
    "\n",
    "bucket = os.environ['WORKSPACE_BUCKET']\n",
    "con = duckdb.connect(\"/tmp/dbt.duckdb\")\n",
    "\n",
    "project_root = Path().resolve().parent\n",
    "sys.path.append(str(project_root))\n",
    "from scripts.general import *\n",
    "paths = get_all_paths(study_id, dbt_repo, org_id, tgt_model_id, src_data_path=None)\n",
    "\n",
    "\n",
    "validation_config = read_file(paths[\"validation_yml_path\"])\n",
    "study_config = read_file(paths[\"study_yml_path\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "src_table_list = list(study_config[\"data_dictionary\"].keys())\n",
    "\n",
    "src_files_list = []\n",
    "datasets = validation_config[\"datasets\"].items()\n",
    "dataset_names = list(validation_config[\"datasets\"].keys())\n",
    "\n",
    "    \n",
    "for table in study_config[\"data_dictionary\"].keys():\n",
    "    for dataset, v in validation_config[\"datasets\"].items():\n",
    "        f_table = table\n",
    "        if v['table_name_swap']:\n",
    "            if f_table in v['table_name_swap'].keys():\n",
    "                f_table = v['table_name_swap'].get(table)\n",
    "        fn = v['filename']\n",
    "        src_files_list.append(f\"{f_table}_{fn}\")\n",
    "        \n",
    "study_files = [f'{study_id}_study.yaml', f'{study_id}_validation.yaml']\n",
    "\n",
    "for dd_table in study_config[\"data_dictionary\"].values():\n",
    "    study_files.append(dd_table['identifier'])\n",
    "    if validation_config[\"bucket_seeds\"]:\n",
    "        for file in validation_config[\"bucket_data_files\"]:\n",
    "            study_files.append(file)\n",
    "\n",
    "seeds_files = []\n",
    "if validation_config[\"bucket_seeds\"]:\n",
    "    for file in validation_config[\"bucket_seeds\"]:\n",
    "        seeds_files.append(file)\n",
    "\n",
    "# print(\"Source Tables:\", src_table_list)\n",
    "# print(\"Source Files List:\", src_files_list)\n",
    "# print(\"Study Files:\", study_files)\n",
    "# print(\"Seed Files:\", seed_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "If starting a new pipeline env\n",
    "- After putting your Private id_rsa key file in the home dir in Terra\n",
    "1. Set up GH and terminal configurations\n",
    "- Run 'run_initial_setup' in this cell\n",
    "- Go to terminal and run:\n",
    "    - 'source ~/.bash_profile' - A list of available commands should show up\n",
    "    - 'setup_ssh'\n",
    "    - 'clone_repo'\n",
    "    - 'setup_data'\n",
    "- At this point you should be able to connect to GitHub and swap branches\n",
    "'''\n",
    "# run_initial_setup(paths, gh_user, gh_email, pipeline)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "'''\n",
    "Get the dds and config files from the bucket\n",
    "'''\n",
    "# get_study_files(study_files, seeds_files, paths) \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Run the following if you only want to pull in the data files from the bucket. Run this \n",
    "if there are no 'partial' files to combine.\n",
    "\"\"\"\n",
    "# copy_data_from_bucket(paths['bucket_study_dir'], src_table_list, paths['src_data_dir'])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "'''\n",
    "Put study files into the bucket.\n",
    "'''\n",
    "store_study_files(study_files, seeds_files, paths)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "'''\n",
    "Export tgt data to csvs in the output dir. Then send the files to the harmonized dir in the bucket\n",
    "'''\n",
    "# copy_to_csv_and_export_to_bucket(tgt_schema, paths)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Convert files in data dir into utf-8. Add to the appropriate list, to save the changes in the bucket.\n",
    "\"\"\"\n",
    "# input_filepath = f'{seeds_dir}/value_sets/RoleCodeValueSet.csv'\n",
    "# output_filepath = f'{seeds_dir}/value_sets/RoleCodeValueSet.csv'\n",
    "# delimiter = '\\t'\n",
    "# encoding = 'latin1'\n",
    "# convert_csv_to_utf8(input_filepath, output_filepath, delimiter, encoding)\n",
    "\n",
    "print('Completed')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.12 (venv)",
   "language": "python",
   "name": "venv-python3.12"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
